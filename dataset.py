import os
import cv2
import pandas as pd
import numpy as np
import torch
import glob
import random
import json
from torch.utils.data import Dataset, Sampler
from tqdm import tqdm
from typing import Optional, Iterator, List
import albumentations as A


class MultiTaskDataset(Dataset):
    def __init__(self, data_root: str, transforms: Optional[A.Compose] = None, task_id: Optional[str] = None,indices=None):
        super().__init__()
        self.data_root = data_root  # project root directory
        self.transforms = transforms
        self.task_id = task_id
        self.csv_path = os.path.join(self.data_root, 'data/train/csv_files')

        # Load all or specified CSVs
        all_csv_files = sorted(glob.glob(os.path.join(self.csv_path, '*.csv')))
        if not all_csv_files:
            raise FileNotFoundError(f"No CSVs found in {self.csv_path}")
        df_list = [pd.read_csv(f) for f in all_csv_files]
        self.dataframe = pd.concat(df_list, ignore_index=True).reset_index(drop=True)

        if task_id:
            self.dataframe = self.dataframe[self.dataframe['task_id'] == task_id].reset_index(drop=True)

        # Finally filter by given indices (split train/val/test from the full pool)
        if indices is not None:
            # Use iloc to extract specified rows and reset index so __getitem__ works correctly
            self.dataframe = self.dataframe.iloc[indices].reset_index(drop=True)

    def __len__(self) -> int:
        return len(self.dataframe)
    def __getitem__(self, idx: int) -> dict:
        record = self.dataframe.iloc[idx]
        task_id = record['task_id']
        task_name = str(record['task_name']).lower()  # unify to lowercase
        num_classes = int(record['num_classes'])

        # 1. Load image (based on root directory)
        image_path = os.path.join(self.data_root, record['image_path'])
        image = cv2.imread(image_path)
        if image is None:
            return self.__getitem__((idx + 1) % len(self))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # 2. Prepare annotation containers
        mask = None
        bboxes = []
        keypoints = []
        class_labels = []

        # 3. Dynamically parse annotations
        if task_name == 'segmentation':
            mask_path = os.path.join(self.data_root, record['mask_path'])
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            # --- Additional defensive code ---
            if mask is None:
                raise FileNotFoundError(
                    f"Failed to read mask file: {mask_path}. Please check whether the suffix in CSV generated by preprocess is correct (e.g. .png).")
            # --------------------

        elif task_name == 'classification':
            pass  # later directly read int(record['mask'])

        elif task_name == 'regression':
            for i in range(1, num_classes + 1):
                col = f'point_{i}_xy'
                pt = json.loads(record[col]) if col in record else [0, 0]
                keypoints.append(pt)  # Albumentations expects [(x,y), (x,y)]

        elif task_name == 'detection':
            for i in range(1, num_classes + 1):
                # Dynamically read x_min_1, y_min_1...
                box = [record[f'x_min_{i}'], record[f'y_min_{i}'],
                       record[f'x_max_{i}'], record[f'y_max_{i}']]
                if sum(box) > 0:  # filter out reserved empty boxes
                    bboxes.append(box + [0])  # 0 is the class index
                    class_labels.append(0)

        # 4. Apply transforms (key: pass all annotations)
        if self.transforms:
            augmented = self.transforms(
                image=image,
                mask=mask,
                bboxes=bboxes,
                keypoints=keypoints,
                class_labels=class_labels
            )
            image = augmented['image']

            # Get transformed image size (tensor shape is C, H, W)
            h_new, w_new = image.shape[1], image.shape[2]

            # 5. Format final label
            if task_name == 'segmentation':
                m_out = augmented['mask']
                # If ToTensorV2 is used in transform, this is already a Tensor
                if isinstance(m_out, torch.Tensor):
                    final_label = m_out.long()
                else:
                    final_label = torch.from_numpy(m_out).long()

                # IMPORTANT: add dimension check:
                # Segmentation label must be [C, H, W], while usually after Argmax it is [H, W]
                # To avoid later loss computation errors, it is recommended to add a channel dimension

            elif task_name == 'classification':
                final_label = torch.tensor(int(record['mask'])).long()

            elif task_name == 'detection':
                # Even if there are multiple boxes, flatten them into fixed length here
                boxes = np.zeros((num_classes, 4), dtype=np.float32)
                if augmented['bboxes']:
                    active_boxes = np.array(augmented['bboxes'])[:, :4]
                    # Normalize
                    active_boxes[:, [0, 2]] /= w_new
                    active_boxes[:, [1, 3]] /= h_new
                    boxes[:len(active_boxes)] = active_boxes
                final_label = torch.from_numpy(boxes).flatten()

            elif task_name == 'regression':
                pts = np.zeros((num_classes, 2), dtype=np.float32)
                if augmented['keypoints']:
                    active_pts = np.array(augmented['keypoints'])
                    active_pts[:, 0] /= w_new
                    active_pts[:, 1] /= h_new
                    pts[:len(active_pts)] = active_pts
                final_label = torch.from_numpy(pts).flatten()

        return {'image': image, 'label': final_label, 'task_id': task_id, 'task_name': task_name}


class MultiTaskUniformSampler(Sampler[List[int]]):
    def __init__(self, dataset: MultiTaskDataset, batch_size: int, steps_per_epoch: Optional[int] = None,seed: int = 42):
        self.dataset = dataset
        self.batch_size = batch_size
        self.seed = seed  # store seed
        self.indices_by_task = {}

        # Fix sampler internal RNG seeds at init
        random.seed(self.seed)  # critical: fix sampler's random seed
        np.random.seed(self.seed)  # optional: also fix numpy RNG if used later

        # Group indices by task_id
        print("\n--- Initializing Sampler ---")
        for idx, task_id in enumerate(tqdm(dataset.dataframe['task_id'], desc="Grouping indices")):
            if task_id not in self.indices_by_task:
                self.indices_by_task[task_id] = []
            self.indices_by_task[task_id].append(idx)
            
        self.task_ids = list(self.indices_by_task.keys())
        
        # Initial shuffle
        for task_id in self.task_ids:
            random.shuffle(self.indices_by_task[task_id])

        # Determine epoch length
        if steps_per_epoch is None:
            self.steps_per_epoch = len(self.dataset) // self.batch_size
        else:
            self.steps_per_epoch = steps_per_epoch

    def __iter__(self) -> Iterator[List[int]]:
        # Reset seeds on every iteration to keep sampling order exactly reproducible
        random.seed(self.seed)
        np.random.seed(self.seed)

        task_cursors = {task_id: 0 for task_id in self.task_ids}

        for _ in range(self.steps_per_epoch):
            # Randomly select a task
            task_id = random.choice(self.task_ids)
            indices = self.indices_by_task[task_id]
            cursor = task_cursors[task_id]
            
            start_idx = cursor
            end_idx = start_idx + self.batch_size
            
            if end_idx > len(indices):
                # Wrap around
                batch_indices = indices[start_idx:]
                random.shuffle(indices)
                remaining = self.batch_size - len(batch_indices)
                batch_indices.extend(indices[:remaining])
                task_cursors[task_id] = remaining
            else:
                batch_indices = indices[start_idx:end_idx]
                task_cursors[task_id] = end_idx
            
            yield batch_indices
            
    def __len__(self) -> int:
        return self.steps_per_epoch